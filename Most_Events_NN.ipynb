{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from root_numpy import root2array, rec2array\n",
    "\n",
    "branch_names = '''Xmomentum,Ymomentum,Momentum,Energy,MvdDEDX,MvdHits,SttMeanDEDX,SttHits,GemHits,\n",
    "TofStopTime,TofM2,TofTrackLength,TofQuality,DrcThetaC,DrcQuality,\n",
    "DiscThetaC,DiscQuality,EmcRawEnergy,EmcCalEnergy,EmcQuality,EmcNumberOfCrystals,\n",
    "EmcNumberOfBumps,EmcModule,EmcZ20,EmcZ53,EmcLat,EmcE1,EmcE9,EmcE25,MuoQuality,MuoIron,\n",
    "MuoMomentumIn,MuoNumberOfLayers,MuoModule,MuoHits,DegreesOfFreedom,ChiSquared,Theta'''.split(\",\")\n",
    "\n",
    "branch_names_2 = '''momentumx,momentumy,momentum,energy,MvdDEDX,MvdHits,SttMeanDEDX,SttHits,GemHits,\\\n",
    "TofStopTime,TofM2,TofTrackLength,TofQuality,DrcThetaC,DrcQuality,\\\n",
    "DiscThetaC,DiscQuality,EmcRawEnergy,EmcCalEnergy,EmcQuality,EmcNumberOfCrystals,\\\n",
    "EmcNumberOfBumps,EmcModule,EmcZ20,EmcZ53,EmcLat,EmcE1,EmcE9,EmcE25,MuoQuality,MuoIron,\\\n",
    "MuoMomentumIn,MuoNumberOfLayers,MuoModule,MuoHits,DegreesOfFreedom,ChiSquared'''.split(\",\")\n",
    "\n",
    "branch_names = [c.strip() for c in branch_names]\n",
    "branch_names = list(branch_names)\n",
    "\n",
    "def loadtrainingdata(name):\n",
    "    filestring=\"/home/lewis/particles/box_500k_\" + name + \".root\"\n",
    "    vals_1 = root2array(filestring, 't1', branch_names)\n",
    "    vals_1 = rec2array(vals_1)\n",
    "    filestring=\"/home/lewis/particles/box_500k_anti_\" + name + \".root\"\n",
    "    vals_2 = root2array(filestring, 't1', branch_names)\n",
    "    vals_2 = rec2array(vals_2)\n",
    "    filestring=\"/home/lewis/particles/evt_500k_\" + name + \".root\"\n",
    "    vals_3 = root2array(filestring, 't1', branch_names)\n",
    "    vals_3 = rec2array(vals_3)\n",
    "    filestring=\"/home/lewis/particles/dpmbkg_1M_\" + name + \".root\"\n",
    "    vals_4 = root2array(filestring, 't1', branch_names)\n",
    "    vals_4 = rec2array(vals_4)[:17644,:]\n",
    "    vals = np.concatenate((vals_1,vals_2,vals_3,vals_4))\n",
    "    print(vals.shape)\n",
    "    return vals\n",
    "\n",
    "def loadtestingdata(name):\n",
    "    filestring=\"/home/lewis/150k_particles/150k/particles/\" + name + \"_150k_tree.root\"\n",
    "    vals_4 = root2array(filestring, 't1', branch_names_2)\n",
    "    vals_4 = rec2array(vals_4)\n",
    "    filestring=\"/home/lewis/150k_particles/150k/antiparticles/P\" + name + \"_theta_150k_tree.root\"\n",
    "    vals_5 = root2array(filestring, 't1', branch_names_2)\n",
    "    vals_5 = rec2array(vals_5)\n",
    "    vals = np.concatenate((vals_4,vals_5))\n",
    "    print (vals.shape)\n",
    "    return vals\n",
    "\n",
    "#for particle in particle_list:\n",
    "electrons = loadtrainingdata('electrons')\n",
    "pions = loadtrainingdata('pions')\n",
    "muons = loadtrainingdata('muons')\n",
    "kaons = loadtrainingdata('kaons')\n",
    "protons = loadtrainingdata('protons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(electrons,pions,muons,kaons,protons,branch_names):\n",
    "    ###################################################################################\n",
    "    X = np.concatenate((electrons, pions, muons, kaons, protons))\n",
    "    y = np.concatenate(( np.zeros(electrons.shape[0]),np.ones(pions.shape[0]), (2*np.ones(muons.shape[0])), (3*np.ones(kaons.shape[0])), (4*np.ones(protons.shape[0])) ))\n",
    "    df = pd.DataFrame(np.hstack((X, y.reshape(y.shape[0], -1))),columns=branch_names+['temp'])\n",
    "    \n",
    "    \n",
    "    # added features\n",
    "    df['Pt'] = np.sqrt( df.loc[:,'Xmomentum']**2  + df.loc[:,'Ymomentum']**2 )\n",
    "    df['EoverP'] = df.loc[:,'EmcCalEnergy']/df.loc[:,'Momentum']\n",
    "\n",
    "    df = df.drop(['Xmomentum'], axis=1)\n",
    "    df = df.drop(['Ymomentum'], axis=1)\n",
    "\n",
    "    df['labels'] = df.loc[:,'temp']\n",
    "    df = df.drop(['temp'], axis=1)\n",
    "    branch_names = list(df.columns.values[0:-1])\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    return df\n",
    "\n",
    "df = createdataframe(electrons,pions,muons,kaons,protons,branch_names)\n",
    "mask = df['Momentum'] < 15\n",
    "df = df[mask]\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(df.iloc[:,0:-1], df.iloc[:,-1], test_size=0.25, random_state=0)\n",
    "\n",
    "xgb = XGBClassifier(max_depth=12, learning_rate=0.15, n_jobs=4, tree_method='exact', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf = xgb.fit(X_train, y_train,verbose=True)\n",
    "print('accuracy on training set: %.2f' % (clf.score(X_train, y_train)*100) + '%')\n",
    "print('accuracy on testing set : %.2f' % (clf.score(X_test, y_test)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "import pickle\n",
    "joblib.dump(clf, '/home/lewis/particles/xgb_1.pkl')\n",
    "print(\"the xgb model has been saved succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Reshape, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(df.iloc[:,0:-1], df.iloc[:,-1], test_size=0.20, random_state=42)\n",
    "\n",
    "# scale the features\n",
    "scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "NComponents = X_train.shape[1]\n",
    "'''\n",
    "# use pca\n",
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.axvline(x=22, color='r')\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "NComponents = 22\n",
    "pca = PCA(n_components=NComponents)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "'''\n",
    "\n",
    "# some variables\n",
    "batch_size = 4096\n",
    "num_classes = 5\n",
    "epochs = 5000\n",
    "\n",
    "# one hot encoding\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(NComponents,)))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "history = model.fit(X_train , y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[EarlyStopping(verbose=True, patience=500, monitor='val_loss')],\n",
    "                    validation_data=(X_test , y_test))\n",
    "\n",
    "t = time.time() - t0\n",
    "\n",
    "print(\"training time = \", t, \" s\")\n",
    "print(\"********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:%.2f' %score[0])\n",
    "print('Test accuracy:%.2f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ann = history.history\n",
    "plt.grid()\n",
    "plt.plot(100 * np.array(ann['acc']), label='training')\n",
    "plt.plot(100 * np.array(ann['val_acc']), label='validation')\n",
    "plt.xlim(0)\n",
    "plt.xlabel('Iterations', fontsize=20)\n",
    "plt.ylabel('Accuracy %', fontsize=20)\n",
    "plt.legend(loc='lower right', fontsize=20)\n",
    "plt.savefig('history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Testing...')\n",
    "yhat = model.predict(X_test, verbose = True, batch_size = 4096)\n",
    "#yhat = model.predict_proba(X_test)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX 5 classes (5 different particles)\n",
    "yhat_cls = np.argmax(yhat, axis=1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,file='0'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_'+file+'.png')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat_cls)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['e','pi','mu','ka','p'],\n",
    "                      normalize=True,\n",
    "                      title='Normalized Confusion Matrix',file='train_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for particle in particle_list:\n",
    "electrons = loadtestingdata('electrons')\n",
    "pions = loadtestingdata('pions')\n",
    "muons = loadtestingdata('muons')\n",
    "kaons = loadtestingdata('kaons')\n",
    "protons = loadtestingdata('protons')\n",
    "\n",
    "df = createdataframe(electrons,pions,muons,kaons,protons,branch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['Theta'], axis=1)\n",
    "X_test, y_test = df.iloc[:,0:-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['Theta'],axis=1)\n",
    "Theta = df.iloc[:,-4]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = scaler.transform(X_test)\n",
    "#X_test = pca.transform(X_test)\n",
    "print ('Testing...')\n",
    "yhat = model.predict(X_test.drop(['Theta'],axis=1), verbose = True, batch_size = 4096)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:%.2f' %score[0])\n",
    "print('Test accuracy:%.2f' % score[1])\n",
    "\n",
    "# CONFUSION MATRIX 5 classes (5 different particles)\n",
    "yhat_cls = np.argmax(yhat,axis=1)\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat_cls)\n",
    "np.set_printoptions(precision=2)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['e','pi','mu','ka','p'],\n",
    "                      normalize=True,\n",
    "                      title='Normalized Confusion Matrix',file='test_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/lewis/particles/model_7.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will find the accuracy of the model for certain momentum ranges\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "pmax = 5.0\n",
    "step_size = 0.05\n",
    "mom_range = np.arange(0.0,pmax+step_size,step_size)\n",
    "\n",
    "thetamax = 180.0\n",
    "theta_step = 2.5\n",
    "theta_range = np.arange(0.0,thetamax+theta_step,theta_step)\n",
    "\n",
    "def accuracy_vs_momentum(pdf,pX_test,py_test):\n",
    "    scores = []\n",
    "    #pX_test = pX_test.drop(['Theta'], axis=1)\n",
    "    for momentum in mom_range:\n",
    "        pmask = (pdf['Momentum'] <= (momentum+step_size)) & (pdf['Momentum'] > momentum)\n",
    "        score = model.evaluate(pX_test[pmask], py_test[pmask], verbose=0)\n",
    "        if not score:\n",
    "            scores.append(0) \n",
    "        else:\n",
    "            scores.append(score[1])\n",
    "    return scores[1:]\n",
    "\n",
    "\n",
    "def accuracy_vs_theta(pdf,pX_test,py_test,Theta):\n",
    "    scores = []\n",
    "    for theta in theta_range:\n",
    "        mask = (Theta <= (theta+theta_step)) & (Theta > theta)\n",
    "        score = model.evaluate(pX_test[mask], py_test[mask], verbose=0)\n",
    "        if not score:\n",
    "            scores.append(0) \n",
    "        else:\n",
    "            scores.append(score[1])\n",
    "    return scores[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the accuracies for the different particles\n",
    "\n",
    "mask = df['labels'] == 0.0\n",
    "e_score = accuracy_vs_momentum(df[mask],X_test[mask],y_test[mask])\n",
    "mask = df['labels'] == 2.0\n",
    "mu_score = accuracy_vs_momentum(df[mask],X_test[mask],y_test[mask])\n",
    "mask = df['labels'] == 1.0\n",
    "pi_score = accuracy_vs_momentum(df[mask],X_test[mask],y_test[mask])\n",
    "mask = df['labels'] == 3.0\n",
    "ka_score = accuracy_vs_momentum(df[mask],X_test[mask],y_test[mask])\n",
    "mask = df['labels'] == 4.0\n",
    "p_score = accuracy_vs_momentum(df[mask],X_test[mask],y_test[mask])\n",
    "mom_range = mom_range[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the model's accuracy versus momentum\n",
    "plt.scatter(mom_range, e_score,s=12,color='aqua', label='$e^{-}$')\n",
    "plt.scatter(mom_range, pi_score,s=12,color='darkorange', label='$\\pi^{-}$')\n",
    "plt.scatter(mom_range, mu_score,s=12,color='cornflowerblue', label='$\\mu^{-}$')\n",
    "plt.scatter(mom_range, ka_score,s=12,color='black', label='$k^{-}$')\n",
    "plt.scatter(mom_range, p_score,s=12,color='green', label='$\\overline{p}$')\n",
    "plt.title('Neural Network Accuracy vs Momentum',fontsize=16)\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,pmax)\n",
    "plt.xlabel('Momentum in GeV/C',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_v_momentum_full.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the accuracies for the different particles\n",
    "\n",
    "mask = df['labels'] == 0.0\n",
    "e_score = accuracy_vs_theta(df[mask],X_test[mask],y_test[mask],Theta[mask])\n",
    "mask = df['labels'] == 2.0\n",
    "mu_score = accuracy_vs_theta(df[mask],X_test[mask],y_test[mask],Theta[mask])\n",
    "mask = df['labels'] == 1.0\n",
    "pi_score = accuracy_vs_theta(df[mask],X_test[mask],y_test[mask],Theta[mask])\n",
    "mask = df['labels'] == 3.0\n",
    "ka_score = accuracy_vs_theta(df[mask],X_test[mask],y_test[mask],Theta[mask])\n",
    "mask = df['labels'] == 4.0\n",
    "p_score = accuracy_vs_theta(df[mask],X_test[mask],y_test[mask],Theta[mask])\n",
    "theta_range = theta_range[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the model's accuracy versus theta\n",
    "plt.scatter(theta_range, e_score,s=12,color='aqua', label='$e^{-}$')\n",
    "plt.scatter(theta_range, pi_score,s=12,color='darkorange', label='$\\pi^{-}$')\n",
    "plt.scatter(theta_range, mu_score,s=12,color='cornflowerblue', label='$\\mu^{-}$')\n",
    "plt.scatter(theta_range, ka_score,s=12,color='black', label='$k^{-}$')\n",
    "plt.scatter(theta_range, p_score,s=12,color='green', label='$\\overline{p}$')\n",
    "plt.title('Neural Network Accuracy vs Theta',fontsize=16)\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,thetamax)\n",
    "plt.xlabel('Theta in Degrees',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.legend(loc='lower center', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_v_theta_full.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load('/home/lewis/particles/xgb_0.pkl')\n",
    "\n",
    "import keras\n",
    "model = keras.models.load_model('/home/lewis/particles/model_5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = clf.predict_proba(X_test)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
    "n_classes = y_test.shape[1]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "lw=2\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='aqua', lw=lw, label='ROC for {0} (area = {1:0.2f})'.format('$e^{-}$',roc_auc[0]))\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange', lw=lw, label='ROC for {0} (area = {1:0.2f})'.format('$\\pi^{-}$',roc_auc[1]))\n",
    "plt.plot(fpr[2], tpr[2], color='cornflowerblue', lw=lw, label='ROC for {0} (area = {1:0.2f})'.format('$\\mu^{-}$',roc_auc[2]))\n",
    "plt.plot(fpr[3], tpr[3], color='black', lw=lw, label='ROC for {0} (area = {1:0.2f})'.format('$k^{-}$',roc_auc[3]))\n",
    "plt.plot(fpr[4], tpr[4], color='green', lw=lw, label='ROC for {0}   (area = {1:0.2f})'.format('$\\overline{p}$',roc_auc[4]))\n",
    "\n",
    "plt.xlim([0.0, 0.5])\n",
    "plt.ylim([0.5, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=22)\n",
    "plt.ylabel('True Positive Rate', fontsize=22)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.savefig('full_roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision recall curve for each class\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = precision_recall_curve(y_test[:, i], y_score[:, i])\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='aqua', lw=lw, label='Electrons')\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange', lw=lw, label='Pions')\n",
    "plt.plot(fpr[2], tpr[2], color='cornflowerblue', lw=lw, label='Muons')\n",
    "plt.plot(fpr[3], tpr[3], color='black', lw=lw, label='Kaons')\n",
    "plt.plot(fpr[4], tpr[4], color='green', lw=lw, label='Protons')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Recall', fontsize=22)\n",
    "plt.ylabel('Precision', fontsize=22)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.savefig('precision_recall_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
